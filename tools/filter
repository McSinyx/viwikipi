#!/usr/bin/env python3
# Filter heavily lossed data
# Copyright (C) 2019  Nguyá»…n Gia Phong
#
# This file is part of viwikipi.
#
# viwikipi is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# viwikipi is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with viwikipi.  If not, see <https://www.gnu.org/licenses/>.

import csv
from argparse import ArgumentParser

from torch import cuda, device, no_grad, tensor
from tqdm import tqdm
from transformers.data import InputExample
from transformers import (
    glue_convert_examples_to_features,
    BertConfig, BertForSequenceClassification, BertTokenizer,
    XLMConfig, XLMForSequenceClassification, XLMTokenizer)

LABELS = ['0', '1']
MODELS = {'bert': (BertConfig, BertForSequenceClassification, BertTokenizer),
          'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer)}
MODEL_LOADERS = {name: tuple(map(lambda cls: cls.from_pretrained, classes))
                 for name, classes in MODELS.items()}
OUTPUT_MODE = 'classification'
TASK = 'mrpc'

FIELDS = 'label', 'qid', 'aid', 'question', 'answer'


def load_model(path, model):
    """Return a tuple of model and tokenizer loaded from given path."""
    cfg, mdl, tok = MODEL_LOADERS[model]
    config = cfg(path, num_labels=len(LABELS))
    return mdl(path, config=config), tok(path, do_lower_case=False)


def convert(label, qid, aid, question, answer):
    """Return a tuple of ID, question and dictionary of paragraphs
    from the given test.
    """
    return qid, question, answer, label


def exampled(tests):
    """Return an iterator of tuples of pair ID and InputExample
    from the given tests.
    """
    next(tests)
    for test in tests: yield test, InputExample(*convert(**test))


parser = ArgumentParser()
parser.add_argument('input', help='input dataset in TSV format')
parser.add_argument('output', help='filtered dataset in TSV format')
parser.add_argument('-t', '--model-type', required=True,
                    choices=MODELS.keys(), help='model type')
parser.add_argument('-m', '--model', required=True,
                    metavar='PATH', help='model directory')
parser.add_argument('-s', '--max-seq', default=256, type=int,
                    metavar='N', help='maximum token sequence length')
parser.add_argument('-l', '--max-loss', default=0.35, type=float,
                    metavar='N', help='maximum loss')
args = parser.parse_args()

model, tokenizer = load_model(args.model, args.model_type)
dev = device('cuda' if cuda.is_available() else 'cpu')
model.to(dev)
with open(args.input) as fi, open(args.output, 'w') as fo:
    reader = csv.DictReader(fi, fieldnames=FIELDS, delimiter='\t')
    rawex, examples = zip(*exampled(reader))
    features = glue_convert_examples_to_features(
        list(examples), tokenizer, max_length=args.max_seq,
        task=TASK, label_list=LABELS, output_mode=OUTPUT_MODE)

    writer = csv.DictWriter(fo, fieldnames=FIELDS, delimiter='\t')
    writer.writeheader()
    with no_grad():
        for ex, feature in zip(tqdm(rawex), features):
            inputs = feature.to_dict()
            del inputs['label']
            for key, value in inputs.items():   # tensorize lists
                inputs[key] = tensor(value).unsqueeze(0).to(dev)
                label = tensor([int(ex['label'])]).to(dev)
                if model(labels=label, **inputs)[0] > args.max_loss:
                    writer.writerow(ex)
