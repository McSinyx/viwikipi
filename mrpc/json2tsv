#!/usr/bin/env python3
# Copyright (C) 2019  Nguyá»…n Gia Phong
#
# This file is part of viwikipi.
#
# viwikipi is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# viwikipi is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with viwikipi.  If not, see <https://www.gnu.org/licenses/>.

import csv
import json
import re
from itertools import islice

from transformers import BertTokenizer

WHITESPACES = re.compile('\s+')

TRAIN_SIZE = 10010
FIELDS = 'label', 'qid', 'aid', 'question', 'answer'

BERT_MODEL = 'bert-base-multilingual-cased'
BERT_TEXT = '[CLS] {question} [SEP] {answer} [SEP]'


def spaced(string):
    """Return the string obtained by replacing all whitespaces by spaces."""
    return WHITESPACES.sub(' ', string).strip()


def standardized(data):
    """Return an itertor of standardized data in MRPC format."""
    for d in data:
        sid = ''.join(c for c in d['id'] if c.isnumeric())
        yield dict(label=int(d['label']), qid=sid+'0', aid=sid+'1',
                   question=spaced(d['question']), answer=spaced(d['text']))


def write(file, dicts):
    """Write dicts to the given file in TSV format."""
    writer = csv.DictWriter(file, FIELDS, delimiter='\t')
    writer.writeheader()
    writer.writerows(dicts)


tokenize = BertTokenizer.from_pretrained(BERT_MODEL).tokenize
with open('train.json') as f:
    data = filter(lambda d: len(tokenize(BERT_TEXT.format(**d))) < 125,
                  standardized(json.load(f)))

with open('train.tsv', 'w') as train, open('dev.tsv', 'w') as dev:
    write(train, islice(data, TRAIN_SIZE))
    write(dev, data)
